import os.path

from libs.helper import *
import streamlit as st
import uuid
import pandas as pd
import openai
from requests.models import ChunkedEncodingError
from streamlit.components import v1
from voice_toolkit import voice_toolkit
import speech_recognition as sr

import google.generativeai as ggi

if "apibase" in st.secrets:
    openai.api_base = st.secrets["apibase"]
else:
    openai.api_base = "https://api.openai.com/v1"

st.set_page_config(
    page_title="AI ì‹¤ë¡",
    layout="wide",
    page_icon=ICON,
)
# css ì„¤ì •
st.markdown(css_code, unsafe_allow_html=True)

if "initial_settings" not in st.session_state:
    # ì±„íŒ… íˆìŠ¤í† ë¦¬
    st.session_state["path"] = "history_chats_file"
    st.session_state["history_chats"] = get_history_chats(st.session_state["path"])
    # ì„¸ì…˜ ì´ˆê¸°í™”
    st.session_state["delete_dict"] = {}
    st.session_state["delete_count"] = 0
    st.session_state["voice_flag"] = ""
    st.session_state["user_voice_value"] = ""
    st.session_state["error_info"] = ""
    st.session_state["current_chat_index"] = 0
    st.session_state["user_input_content"] = ""
    # ì „ì—­ ë³€ìˆ˜ ì„¤ì •
    if os.path.exists("./set.json"):
        with open("./set.json", "r", encoding="utf-8") as f:
            data_set = json.load(f)
        for key, value in data_set.items():
            st.session_state[key] = value
    # ì„¤ì • ì™„ë£Œ
    st.session_state["initial_settings"] = True

with st.sidebar:
    icon_text = f"""
    <div class="icon-text-container">
        <img src='data:image/png;base64,{ICON_base64}' alt='icon'>
        <span style='font-size: 24px;'>AI ì‹¤ë¡</span>
    </div>
    """
    st.markdown(
        icon_text,
        unsafe_allow_html=True,
    )
    # åˆ›å»ºå®¹å™¨çš„ç›®çš„æ˜¯é…åˆè‡ªå®šä¹‰ç»„ä»¶çš„ç›‘å¬æ“ä½œ
    chat_container = st.container()
    with chat_container:
        current_chat = st.radio(
            label="ì±„íŒ…ì°½",
            format_func=lambda x: x.split("_")[0] if "_" in x else x,
            options=st.session_state["history_chats"],
            label_visibility="collapsed",
            index=st.session_state["current_chat_index"],
            key="current_chat"
            + st.session_state["history_chats"][st.session_state["current_chat_index"]],
            # on_change=current_chat_callback  
        )
    st.write("---")


#  íŒŒì¼ ë°ì´í„° ì“°ê¸°
def write_data(new_chat_name=current_chat):
    if "apikey" in st.secrets:
        st.session_state["paras"] = {
            "temperature": st.session_state["temperature" + current_chat],
            "top_p": st.session_state["top_p" + current_chatcurrent_chat],
            "presence_penalty": st.session_state["presence_penalty" + current_chat],
            "frequency_penalty": st.session_state["frequency_penalty" + current_chat],
        }
        st.session_state["contexts"] = {
            "context_select": st.session_state["context_select" + current_chat],
            "context_input": st.session_state["context_input" + current_chat],
            "context_level": st.session_state["context_level" + current_chat],
        }
        save_data(
            st.session_state["path"],
            new_chat_name,
            st.session_state["history" + current_chat],
            st.session_state["paras"],
            st.session_state["contexts"],
        )


def reset_chat_name_fun(chat_name):
    chat_name = chat_name + "_" + str(uuid.uuid4())
    new_name = filename_correction(chat_name)
    current_chat_index = st.session_state["history_chats"].index(current_chat)
    st.session_state["history_chats"][current_chat_index] = new_name
    st.session_state["current_chat_index"] = current_chat_index
    # ìƒˆ íŒŒì¼ ì“°ê¸°
    write_data(new_name)
    # ë°ì´í„° ì´ë™
    st.session_state["history" + new_name] = st.session_state["history" + current_chat]
    for item in [
        "context_select",
        "context_input",
        "context_level",
        *initial_content_all["paras"],
    ]:
        st.session_state[item + new_name + "value"] = st.session_state[
            item + current_chat + "value"
        ]
    remove_data(st.session_state["path"], current_chat)


def create_chat_fun():
    st.session_state["history_chats"] = [
        "New Chat_" + str(uuid.uuid4())
    ] + st.session_state["history_chats"]
    st.session_state["current_chat_index"] = 0


def delete_chat_fun():
    if len(st.session_state["history_chats"]) == 1:
        chat_init = "New Chat_" + str(uuid.uuid4())
        st.session_state["history_chats"].append(chat_init)
    pre_chat_index = st.session_state["history_chats"].index(current_chat)
    if pre_chat_index > 0:
        st.session_state["current_chat_index"] = (
            st.session_state["history_chats"].index(current_chat) - 1
        )
    else:
        st.session_state["current_chat_index"] = 0
    st.session_state["history_chats"].remove(current_chat)
    remove_data(st.session_state["path"], current_chat)


with st.sidebar:
    c1, c2 = st.columns(2)
    create_chat_button = c1.button(
        "ì‹ ê·œ ì±„íŒ…", use_container_width=True, key="create_chat_button"
    )
    if create_chat_button:
        create_chat_fun()
        st.rerun()

    delete_chat_button = c2.button(
        "   ì‚­ì œ", use_container_width=True, key="delete_chat_button"
    )
    if delete_chat_button:
        delete_chat_fun()
        st.rerun()

with st.sidebar:
    if ("set_chat_name" in st.session_state) and st.session_state[
        "set_chat_name"
    ] != "":
        reset_chat_name_fun(st.session_state["set_chat_name"])
        st.session_state["set_chat_name"] = ""
        st.rerun()

    st.write("\n")
    st.text_input("ì±„íŒ…ë°© ì´ë¦„ ì„¤ì •ï¼š", key="set_chat_name", placeholder="ì±„íŒ…ë°© ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
    st.selectbox(
        "LLM ëª¨ë¸ì„ íƒï¼š",
        index=0,
        options=["gemini-1.5-flash","gpt-4o-mini", "gpt-3.5-turbo", "gpt-4-turbo", "gpt-4o", "gpt-4"],
        key="select_model",
    )
    
    st.caption(
        """
    - Ctrl + Enter ì…ë ¥
    """
    )


# ì±„íŒ… íˆìŠ¤í† ë¦¬ ë°ì´í„° ë¡œë“œ
if "history" + current_chat not in st.session_state:
    for key, value in load_data(st.session_state["path"], current_chat).items():
        if key == "history":
            st.session_state[key + current_chat] = value
        else:
            for k, v in value.items():
                st.session_state[k + current_chat + "value"] = v

# ä¿è¯ä¸åŒchatçš„é¡µé¢å±‚æ¬¡ä¸€è‡´ï¼Œå¦åˆ™ä¼šå¯¼è‡´è‡ªå®šä¹‰ç»„ä»¶é‡æ–°æ¸²æŸ“
container_show_messages = st.container()
container_show_messages.write("")
#ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
with container_show_messages:
    if st.session_state["history" + current_chat]:
        show_messages(current_chat, st.session_state["history" + current_chat])

# ì‚­ì œí•  ì±„íŒ…ì°½ ì„ íƒ
if any(st.session_state["delete_dict"].values()):
    for key, value in st.session_state["delete_dict"].items():
        try:
            deleteCount = value.get("deleteCount")
        except AttributeError:
            deleteCount = None
        if deleteCount == st.session_state["delete_count"]:
            delete_keys = key
            st.session_state["delete_count"] = deleteCount + 1
            delete_current_chat, idr = delete_keys.split(">")
            df_history_tem = pd.DataFrame(
                st.session_state["history" + delete_current_chat]
            )
            df_history_tem.drop(
                index=df_history_tem.query("role=='user'").iloc[[int(idr)], :].index,
                inplace=True,
            )
            df_history_tem.drop(
                index=df_history_tem.query("role=='assistant'")
                .iloc[[int(idr)], :]
                .index,
                inplace=True,
            )
            st.session_state["history" + delete_current_chat] = df_history_tem.to_dict(
                "records"
            )
            write_data()
            st.rerun()


def callback_fun(arg):
    if ("history" + current_chat in st.session_state) and (
        "frequency_penalty" + current_chat in st.session_state
    ):
        write_data()
        st.session_state[arg + current_chat + "value"] = st.session_state[
            arg + current_chat
        ]


def clear_button_callback():
    st.session_state["history" + current_chat] = []
    write_data()


def delete_all_chat_button_callback():
    if "apikey" in st.secrets:
        folder_path = st.session_state["path"]
        file_list = os.listdir(folder_path)
        for file_name in file_list:
            file_path = os.path.join(folder_path, file_name)
            if file_name.endswith(".json") and os.path.isfile(file_path):
                os.remove(file_path)
    st.session_state["current_chat_index"] = 0
    st.session_state["history_chats"] = ["New Chat_" + str(uuid.uuid4())]

def get_audio_input():
        r = sr.Recognizer()

        with sr.Microphone() as source:
            audio = r.listen(source)

        # êµ¬ê¸€ ì›¹ ìŒì„± APIë¡œ ì¸ì‹í•˜ê¸° 
        try:
            print("Google Speech Recognition thinks you said : " + r.recognize_google(audio, language='ko'))
            return r.recognize_google(audio, language='ko')
        except sr.UnknownValueError as e:
            print("Google Speech Recognition could not understand audio".format(e))
            return None
        except sr.RequestError as e:
            print("Could not request results from Google Speech Recognition service; {0}".format(e))
            return None

def save_set(arg):
    st.session_state[arg + "_value"] = st.session_state[arg]
    if "apikey" in st.secrets:
        with open("./set.json", "w", encoding="utf-8") as f:
            json.dump(
                {
                    "open_text_toolkit_value": st.session_state["open_text_toolkit"],
                    "open_voice_toolkit_value": st.session_state["open_voice_toolkit"],
                },
                f,
            )


# ì…ë ¥ì°½ í‘œì¶œ
area_user_svg = st.empty()
area_user_content = st.empty()
# ë‹µë³€ í‘œì¶œ
area_gpt_svg = st.empty()
area_gpt_content = st.empty()
# ì˜¤ë¥˜ ë©”ì„¸ì§€ í‘œì¶œ
area_error = st.empty()

st.write("\n")
st.header("AI ì‹¤ë¡")
tap_input, tap_context, tap_model, tab_func = st.tabs(
    ["ğŸ’¬ ì±„íŒ…", "ğŸ—’ï¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •", "âš™ï¸ LLM ëª¨ë¸", "ğŸ› ï¸ ì¶”ê°€ ê¸°ëŠ¥"]
)

with tap_context:
    set_context_list = list(set_context_all.keys())
    context_select_index = set_context_list.index(
        st.session_state["context_select" + current_chat + "value"]
    )
    st.selectbox(
        label="í”„ë¡¬í”„íŠ¸ ì„ íƒ",
        options=set_context_list,
        key="context_select" + current_chat,
        index=context_select_index,
        on_change=callback_fun,
        args=("context_select",),
    )
    st.caption(set_context_all[st.session_state["context_select" + current_chat]])

    st.text_area(
        label="ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° ì¶”ê°€:",
        key="context_input" + current_chat,
        value=st.session_state["context_input" + current_chat + "value"],
        on_change=callback_fun,
        args=("context_input",),
    )

with tap_model:
    st.markdown("OpenAI/Gemini API Key ì…ë ¥")
    st.text_input(
        "OpenAI API Key",
        type="password",
        key="apikey_input",
        label_visibility="collapsed",
    )

    st.slider(
        "Context Level",
        0,
        10,
        st.session_state["context_level" + current_chat + "value"],
        1,
        on_change=callback_fun,
        key="context_level" + current_chat,
        args=("context_level",),
        help="ê° ì„¸ì…˜ì— í¬í•¨ëœ ê³¼ê±° ëŒ€í™” íšŸìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ë¯¸ë¦¬ ì„¤ì •ëœ ë‚´ìš©ì€ í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
    )

    with st.expander("ëª¨ë¸ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„¤ì •ï¼š"):
        st.slider(
            "Temperature",
            0.0,
            2.0,
            st.session_state["temperature" + current_chat + "value"],
            0.1,
            help="""åœ¨0å’Œ2ä¹‹é—´ï¼Œåº”è¯¥ä½¿ç”¨ä»€ä¹ˆæ ·çš„é‡‡æ ·æ¸©åº¦ï¼Ÿè¾ƒé«˜çš„å€¼ï¼ˆå¦‚0.8ï¼‰ä¼šä½¿è¾“å‡ºæ›´éšæœºï¼Œè€Œè¾ƒä½çš„å€¼ï¼ˆå¦‚0.2ï¼‰åˆ™ä¼šä½¿å…¶æ›´åŠ é›†ä¸­å’Œç¡®å®šæ€§ã€‚
              æˆ‘ä»¬ä¸€èˆ¬å»ºè®®åªæ›´æ”¹è¿™ä¸ªå‚æ•°æˆ–top_på‚æ•°ä¸­çš„ä¸€ä¸ªï¼Œè€Œä¸è¦åŒæ—¶æ›´æ”¹ä¸¤ä¸ªã€‚""",
            on_change=callback_fun,
            key="temperature" + current_chat,
            args=("temperature",),
        )
        st.slider(
            "Top P",
            0.1,
            1.0,
            st.session_state["top_p" + current_chat + "value"],
            0.1,
            help="""ä¸€ç§æ›¿ä»£é‡‡ç”¨æ¸©åº¦è¿›è¡Œé‡‡æ ·çš„æ–¹æ³•ï¼Œç§°ä¸ºâ€œåŸºäºæ ¸å¿ƒæ¦‚ç‡â€çš„é‡‡æ ·ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œæ¨¡å‹ä¼šè€ƒè™‘æ¦‚ç‡æœ€é«˜çš„top_pä¸ªæ ‡è®°çš„é¢„æµ‹ç»“æœã€‚
              å› æ­¤ï¼Œå½“è¯¥å‚æ•°ä¸º0.1æ—¶ï¼Œåªæœ‰åŒ…æ‹¬å‰10%æ¦‚ç‡è´¨é‡çš„æ ‡è®°å°†è¢«è€ƒè™‘ã€‚æˆ‘ä»¬ä¸€èˆ¬å»ºè®®åªæ›´æ”¹è¿™ä¸ªå‚æ•°æˆ–é‡‡æ ·æ¸©åº¦å‚æ•°ä¸­çš„ä¸€ä¸ªï¼Œè€Œä¸è¦åŒæ—¶æ›´æ”¹ä¸¤ä¸ªã€‚""",
            on_change=callback_fun,
            key="top_p" + current_chat,
            args=("top_p",),
        )
        st.slider(
            "Presence Penalty",
            -2.0,
            2.0,
            st.session_state["presence_penalty" + current_chat + "value"],
            0.1,
            help="""è¯¥å‚æ•°çš„å–å€¼èŒƒå›´ä¸º-2.0åˆ°2.0ã€‚æ­£å€¼ä¼šæ ¹æ®æ–°æ ‡è®°æ˜¯å¦å‡ºç°åœ¨å½“å‰ç”Ÿæˆçš„æ–‡æœ¬ä¸­å¯¹å…¶è¿›è¡Œæƒ©ç½šï¼Œä»è€Œå¢åŠ æ¨¡å‹è°ˆè®ºæ–°è¯é¢˜çš„å¯èƒ½æ€§ã€‚""",
            on_change=callback_fun,
            key="presence_penalty" + current_chat,
            args=("presence_penalty",),
        )
        st.slider(
            "Frequency Penalty",
            -2.0,
            2.0,
            st.session_state["frequency_penalty" + current_chat + "value"],
            0.1,
            help="""è¯¥å‚æ•°çš„å–å€¼èŒƒå›´ä¸º-2.0åˆ°2.0ã€‚æ­£å€¼ä¼šæ ¹æ®æ–°æ ‡è®°åœ¨å½“å‰ç”Ÿæˆçš„æ–‡æœ¬ä¸­çš„å·²æœ‰é¢‘ç‡å¯¹å…¶è¿›è¡Œæƒ©ç½šï¼Œä»è€Œå‡å°‘æ¨¡å‹ç›´æ¥é‡å¤ç›¸åŒè¯­å¥çš„å¯èƒ½æ€§ã€‚""",
            on_change=callback_fun,
            key="frequency_penalty" + current_chat,
            args=("frequency_penalty",),
        )

with tab_func:
    c1, c2, c3 = st.columns(3)
    with c1:
        st.button(
            "ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°", use_container_width=True, on_click=clear_button_callback
        )
    with c2:
        btn = st.download_button(
            label="ì±„íŒ… ê¸°ë¡ ë‚´ë³´ë‚´ê¸°",
            data=download_history(st.session_state["history" + current_chat]),
            file_name=f'{current_chat.split("_")[0]}.md',
            mime="text/markdown",
            use_container_width=True,
        )
    with c3:
        st.button(
            "ëª¨ë“  ë°ì´í„° ì‚­ì œ",
            use_container_width=True,
            on_click=delete_all_chat_button_callback,
        )

    st.write("\n")
    st.markdown("ë§ì¶¤ ê¸°ëŠ¥ï¼š")
    c1, c2 = st.columns(2)
    with c1:
        if "open_text_toolkit_value" in st.session_state:
            default = st.session_state["open_text_toolkit_value"]
        else:
            default = True
        st.checkbox(
            "í…ìŠ¤íŠ¸ ì•„ë˜ì˜ ê¸°ëŠ¥ êµ¬ì„± ìš”ì†Œë¥¼ ì¼œì‹­ì‹œì˜¤.",
            value=default,
            key="open_text_toolkit",
            on_change=save_set,
            args=("open_text_toolkit",),
        )
    with c2:
        if "open_voice_toolkit_value" in st.session_state:
            default = st.session_state["open_voice_toolkit_value"]
        else:
            default = True
        st.checkbox(
            "ìŒì„± ì…ë ¥ ì»´í¬ë„ŒíŠ¸ë¥¼ ì¼œì„¸ìš”",
            value=default,
            key="open_voice_toolkit",
            on_change=save_set,
            args=("open_voice_toolkit",),
        )

with tap_input:

    def input_callback():
        if st.session_state["user_input_area"] != "":
            # ä¿®æ”¹çª—å£åç§°
            user_input_content = st.session_state["user_input_area"]
            df_history = pd.DataFrame(st.session_state["history" + current_chat])
            if df_history.empty or len(df_history.query('role!="system"')) == 0:
                new_name = extract_chars(user_input_content, 18)
                reset_chat_name_fun(new_name)

    with st.form("input_form", clear_on_submit=True):
        user_input = st.text_area(
            "**ì…ë ¥**",
            key="user_input_area",
            help="å†…å®¹å°†ä»¥Markdownæ ¼å¼åœ¨é¡µé¢å±•ç¤ºï¼Œå»ºè®®éµå¾ªç›¸å…³è¯­è¨€è§„èŒƒï¼ŒåŒæ ·æœ‰åˆ©äºGPTæ­£ç¡®è¯»å–ï¼Œä¾‹å¦‚ï¼š"
            "\n- ä»£ç å—å†™åœ¨ä¸‰ä¸ªåå¼•å·å†…ï¼Œå¹¶æ ‡æ³¨è¯­è¨€ç±»å‹"
            "\n- ä»¥è‹±æ–‡å†’å·å¼€å¤´çš„å†…å®¹æˆ–è€…æ­£åˆ™è¡¨è¾¾å¼ç­‰å†™åœ¨å•åå¼•å·å†…",
            value=st.session_state["user_voice_value"],
        )
        submitted = st.form_submit_button(
            "ììœ ë¡­ê²Œ ëŒ€í™”í•´ë³´ì„¸ìš”", use_container_width=True, on_click=input_callback
        )
    if st.button("ë§ˆì´í¬ ì¼œê¸°"):
        google_voice_input = get_audio_input()
        if google_voice_input is not None:
            st.session_state["user_voice_value"] = google_voice_input
            st.session_state["voice_flag"] = "final"
            st.rerun()

    if submitted:
        st.session_state["user_input_content"] = user_input
        st.session_state["user_voice_value"] = ""
        st.rerun()

    if (
        "open_voice_toolkit_value" not in st.session_state
        or st.session_state["open_voice_toolkit_value"]
    ):
        # ìŒì„± ì…ë ¥ ê¸°ëŠ¥
        vocie_result = voice_toolkit()

        # vocie_result ë§ˆì§€ë§‰ ê²°ê³¼ ì €ì¥
        if (
            vocie_result and vocie_result["voice_result"]["flag"] == "interim"
        ) or st.session_state["voice_flag"] == "interim":
            st.session_state["voice_flag"] = "interim"
            st.session_state["user_voice_value"] = vocie_result["voice_result"]["value"]
            if vocie_result["voice_result"]["flag"] == "final":
                st.session_state["voice_flag"] = "final"
                st.rerun()


def get_model_input():
    # íˆìŠ¤í† ë¦¬ ì…ë ¥
    context_level = st.session_state["context_level" + current_chat]
    history = get_history_input(
        st.session_state["history" + current_chat], context_level
    ) + [{"role": "user", "content": st.session_state["pre_user_input_content"]}]
    for ctx in [
        st.session_state["context_input" + current_chat],
        set_context_all[st.session_state["context_select" + current_chat]],
    ]:
        if ctx != "":
            history = [{"role": "system", "content": ctx}] + history
    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    paras = {
        "temperature": st.session_state["temperature" + current_chat],
        "top_p": st.session_state["top_p" + current_chat],
        "presence_penalty": st.session_state["presence_penalty" + current_chat],
        "frequency_penalty": st.session_state["frequency_penalty" + current_chat],
    }
    return history, paras


if st.session_state["user_input_content"] != "":
    if "r" in st.session_state:
        st.session_state.pop("r")
        st.session_state[current_chat + "report"] = ""
    st.session_state["pre_user_input_content"] = st.session_state["user_input_content"]
    st.session_state["user_input_content"] = ""
    # ì„ì‹œ í‘œì¶œ
    show_each_message(
        st.session_state["pre_user_input_content"],
        "user",
        "tem",
        [area_user_svg.markdown, area_user_content.markdown],
    )
    # ëª¨ë¸ ì…ë ¥
    history_need_input, paras_need_input = get_model_input()
    # ë‹µë³€ í˜¸ì¶œ
    with st.spinner("ğŸ¤”"):
        try:
            if apikey := st.session_state["apikey_input"]:
                openai.api_key = apikey
            elif "apikey_tem" in st.secrets:
                openai.api_key = st.secrets["apikey_tem"]
            else:
                openai.api_key = st.secrets["apikey"]
                
            select_model = st.session_state["select_model"]

            if select_model == "gemini-1.5-flash":
                print(openai.api_key)
                print(paras_need_input)
                print(history_need_input)
                print(history_need_input[0]["content"])
                ggi.configure(api_key = openai.api_key)
                model = ggi.GenerativeModel(select_model) 
                chat = model.start_chat()
                r = chat.send_message(history_need_input[0]["content"],stream=True)
                print(r)

            else:
                r = openai.ChatCompletion.create(
                model=st.session_state["select_model"],
                messages=history_need_input,
                stream=True,
                **paras_need_input,
                )
        except (FileNotFoundError, KeyError):
            area_error.error(
                "OpenAI/Gemini API Keyë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”"
            )
        except openai.error.AuthenticationError:
            area_error.error("ìœ íš¨í•˜ì§€ ì•Šì€ OpenAI API Keyã€‚")
        except openai.error.APIConnectionError as e:
            area_error.error("ì—°ê²° ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤, ë‹¤ì‹œ ì‹œë„í•˜ì‹­ì‹œì˜¤. ì—ëŸ¬ï¼š   \n" + str(e.args[0]))
        except openai.error.InvalidRequestError as e:
            area_error.error("ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì‹­ì‹œì˜¤. ì—ëŸ¬ï¼š   \n" + str(e.args[0]))
        except openai.error.RateLimitError as e:
            area_error.error("ìš”ì²­ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤. ì—ëŸ¬ ï¼š   \n" + str(e.args[0]))
        else:
            st.session_state["chat_of_r"] = current_chat
            print(current_chat)
            st.session_state["r"] = r
            st.rerun()

if ("r" in st.session_state) and (current_chat == st.session_state["chat_of_r"]):
    select_model = st.session_state["select_model"]
    if current_chat + "report" not in st.session_state:
        st.session_state[current_chat + "report"] = ""
    try:
        if select_model == "gemini-1.5-flash":
            print("gemini start")
            # Gemini API response handling
            for chunk in st.session_state["r"]:
                st.session_state[current_chat + "report"] += chunk.text
                show_each_message(
                    st.session_state["pre_user_input_content"],
                    "user",
                    "tem",
                    [area_user_svg.markdown, area_user_content.markdown],
                )
                show_each_message(
                    st.session_state[current_chat + "report"],
                    "assistant",
                    "tem",
                    [area_gpt_svg.markdown, area_gpt_content.markdown],
                )
        else:            
            for e in st.session_state["r"]:
                if "content" in e["choices"][0]["delta"]:
                    st.session_state[current_chat + "report"] += e["choices"][0]["delta"][
                        "content"
                    ]
                    show_each_message(
                       st.session_state["pre_user_input_content"],
                      "user",
                      "tem",
                     [area_user_svg.markdown, area_user_content.markdown],
                    )
                    show_each_message(
                      st.session_state[current_chat + "report"],
                     "assistant",
                     "tem",
                        [area_gpt_svg.markdown, area_gpt_content.markdown],
                    )

    except ChunkedEncodingError:
        area_error.error("ë„¤íŠ¸ì›Œí¬ ìƒíƒœê°€ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤, í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì‹­ì‹œì˜¤.")
    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
        # Log the error for further analysis
        print(f"Error: {str(e)}")
    else:
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        st.session_state["history" + current_chat].append(
            {"role": "user", "content": st.session_state["pre_user_input_content"]}
        )
        st.session_state["history" + current_chat].append(
            {"role": "assistant", "content": st.session_state[current_chat + "report"]}
        )
        write_data()
    
    if current_chat + "report" in st.session_state:
        st.session_state.pop(current_chat + "report")
    if "r" in st.session_state:
        st.session_state.pop("r")
        st.rerun()
        
# ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€
v1.html(js_code, height=0)
